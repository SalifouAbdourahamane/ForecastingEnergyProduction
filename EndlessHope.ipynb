{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c876b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.413168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 293076, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 117.679737\n",
      "0:\tlearn: 152.8061054\ttotal: 733ms\tremaining: 3m 39s\n",
      "1:\tlearn: 137.7112882\ttotal: 1.32s\tremaining: 3m 16s\n",
      "2:\tlearn: 124.0999966\ttotal: 1.83s\tremaining: 3m 1s\n",
      "3:\tlearn: 111.8863346\ttotal: 2.28s\tremaining: 2m 48s\n",
      "4:\tlearn: 100.9443232\ttotal: 2.61s\tremaining: 2m 33s\n",
      "5:\tlearn: 91.0351237\ttotal: 3.07s\tremaining: 2m 30s\n",
      "6:\tlearn: 82.1284492\ttotal: 3.74s\tremaining: 2m 36s\n",
      "7:\tlearn: 74.1154725\ttotal: 4.31s\tremaining: 2m 37s\n",
      "8:\tlearn: 66.9512809\ttotal: 4.9s\tremaining: 2m 38s\n",
      "9:\tlearn: 60.4969341\ttotal: 5.44s\tremaining: 2m 37s\n",
      "10:\tlearn: 54.7052550\ttotal: 5.99s\tremaining: 2m 37s\n",
      "11:\tlearn: 49.4942620\ttotal: 6.56s\tremaining: 2m 37s\n",
      "12:\tlearn: 44.7925639\ttotal: 7.05s\tremaining: 2m 35s\n",
      "13:\tlearn: 40.5737249\ttotal: 7.54s\tremaining: 2m 33s\n",
      "14:\tlearn: 36.8205600\ttotal: 8.11s\tremaining: 2m 34s\n",
      "15:\tlearn: 33.4856029\ttotal: 8.66s\tremaining: 2m 33s\n",
      "16:\tlearn: 30.5010503\ttotal: 9.2s\tremaining: 2m 33s\n",
      "17:\tlearn: 27.8081677\ttotal: 9.7s\tremaining: 2m 31s\n",
      "18:\tlearn: 25.3903120\ttotal: 10.2s\tremaining: 2m 30s\n",
      "19:\tlearn: 23.2907117\ttotal: 10.7s\tremaining: 2m 29s\n",
      "20:\tlearn: 21.3779301\ttotal: 11.2s\tremaining: 2m 29s\n",
      "21:\tlearn: 19.7011042\ttotal: 11.8s\tremaining: 2m 28s\n",
      "22:\tlearn: 18.2123752\ttotal: 12.3s\tremaining: 2m 27s\n",
      "23:\tlearn: 16.9051608\ttotal: 12.8s\tremaining: 2m 27s\n",
      "24:\tlearn: 15.7791258\ttotal: 13.3s\tremaining: 2m 26s\n",
      "25:\tlearn: 14.7792736\ttotal: 13.8s\tremaining: 2m 25s\n",
      "26:\tlearn: 13.9263833\ttotal: 14.3s\tremaining: 2m 24s\n",
      "27:\tlearn: 13.1502896\ttotal: 14.9s\tremaining: 2m 24s\n",
      "28:\tlearn: 12.5009314\ttotal: 15.4s\tremaining: 2m 23s\n",
      "29:\tlearn: 11.9237655\ttotal: 15.9s\tremaining: 2m 23s\n",
      "30:\tlearn: 11.4121504\ttotal: 16.5s\tremaining: 2m 23s\n",
      "31:\tlearn: 10.9891101\ttotal: 17.1s\tremaining: 2m 22s\n",
      "32:\tlearn: 10.6005286\ttotal: 17.6s\tremaining: 2m 22s\n",
      "33:\tlearn: 10.2571476\ttotal: 18.2s\tremaining: 2m 22s\n",
      "34:\tlearn: 9.9882558\ttotal: 18.6s\tremaining: 2m 20s\n",
      "35:\tlearn: 9.7238435\ttotal: 19.2s\tremaining: 2m 20s\n",
      "36:\tlearn: 9.5296948\ttotal: 19.7s\tremaining: 2m 20s\n",
      "37:\tlearn: 9.3666791\ttotal: 20.2s\tremaining: 2m 19s\n",
      "38:\tlearn: 9.2187071\ttotal: 20.8s\tremaining: 2m 18s\n",
      "39:\tlearn: 9.0885772\ttotal: 21.3s\tremaining: 2m 18s\n",
      "40:\tlearn: 8.9911531\ttotal: 21.8s\tremaining: 2m 17s\n",
      "41:\tlearn: 8.8865619\ttotal: 22.3s\tremaining: 2m 17s\n",
      "42:\tlearn: 8.7866072\ttotal: 22.8s\tremaining: 2m 16s\n",
      "43:\tlearn: 8.6986604\ttotal: 23.3s\tremaining: 2m 15s\n",
      "44:\tlearn: 8.6234116\ttotal: 23.8s\tremaining: 2m 14s\n",
      "45:\tlearn: 8.5756780\ttotal: 24.3s\tremaining: 2m 14s\n",
      "46:\tlearn: 8.5247228\ttotal: 24.8s\tremaining: 2m 13s\n",
      "47:\tlearn: 8.4764859\ttotal: 25.3s\tremaining: 2m 12s\n",
      "48:\tlearn: 8.4319339\ttotal: 25.7s\tremaining: 2m 11s\n",
      "49:\tlearn: 8.3809499\ttotal: 26.2s\tremaining: 2m 11s\n",
      "50:\tlearn: 8.3134761\ttotal: 26.8s\tremaining: 2m 10s\n",
      "51:\tlearn: 8.2604981\ttotal: 27.2s\tremaining: 2m 9s\n",
      "52:\tlearn: 8.2337345\ttotal: 27.7s\tremaining: 2m 9s\n",
      "53:\tlearn: 8.2078736\ttotal: 28.3s\tremaining: 2m 8s\n",
      "54:\tlearn: 8.1931873\ttotal: 28.8s\tremaining: 2m 8s\n",
      "55:\tlearn: 8.1617881\ttotal: 29.4s\tremaining: 2m 7s\n",
      "56:\tlearn: 8.1272322\ttotal: 30s\tremaining: 2m 7s\n",
      "57:\tlearn: 8.0929623\ttotal: 30.5s\tremaining: 2m 7s\n",
      "58:\tlearn: 8.0808642\ttotal: 30.9s\tremaining: 2m 6s\n",
      "59:\tlearn: 8.0576394\ttotal: 31.3s\tremaining: 2m 5s\n",
      "60:\tlearn: 8.0392339\ttotal: 31.9s\tremaining: 2m 4s\n",
      "61:\tlearn: 8.0182717\ttotal: 32.4s\tremaining: 2m 4s\n",
      "62:\tlearn: 8.0009933\ttotal: 32.9s\tremaining: 2m 3s\n",
      "63:\tlearn: 7.9884838\ttotal: 33.5s\tremaining: 2m 3s\n",
      "64:\tlearn: 7.9558371\ttotal: 34s\tremaining: 2m 3s\n",
      "65:\tlearn: 7.9377697\ttotal: 34.5s\tremaining: 2m 2s\n",
      "66:\tlearn: 7.9122519\ttotal: 34.9s\tremaining: 2m 1s\n",
      "67:\tlearn: 7.8833570\ttotal: 35.4s\tremaining: 2m\n",
      "68:\tlearn: 7.8678727\ttotal: 35.9s\tremaining: 2m\n",
      "69:\tlearn: 7.8442217\ttotal: 36.5s\tremaining: 1m 59s\n",
      "70:\tlearn: 7.8194239\ttotal: 37.1s\tremaining: 1m 59s\n",
      "71:\tlearn: 7.8022555\ttotal: 37.6s\tremaining: 1m 58s\n",
      "72:\tlearn: 7.7894387\ttotal: 38s\tremaining: 1m 58s\n",
      "73:\tlearn: 7.7676041\ttotal: 38.6s\tremaining: 1m 57s\n",
      "74:\tlearn: 7.7330780\ttotal: 39.1s\tremaining: 1m 57s\n",
      "75:\tlearn: 7.7128707\ttotal: 39.6s\tremaining: 1m 56s\n",
      "76:\tlearn: 7.6990755\ttotal: 40.1s\tremaining: 1m 56s\n",
      "77:\tlearn: 7.6654891\ttotal: 40.6s\tremaining: 1m 55s\n",
      "78:\tlearn: 7.6487428\ttotal: 41.1s\tremaining: 1m 55s\n",
      "79:\tlearn: 7.6344087\ttotal: 41.6s\tremaining: 1m 54s\n",
      "80:\tlearn: 7.6095432\ttotal: 42.2s\tremaining: 1m 54s\n",
      "81:\tlearn: 7.5901004\ttotal: 42.7s\tremaining: 1m 53s\n",
      "82:\tlearn: 7.5719339\ttotal: 43.3s\tremaining: 1m 53s\n",
      "83:\tlearn: 7.5533690\ttotal: 43.8s\tremaining: 1m 52s\n",
      "84:\tlearn: 7.5437699\ttotal: 44.3s\tremaining: 1m 52s\n",
      "85:\tlearn: 7.5252852\ttotal: 44.9s\tremaining: 1m 51s\n",
      "86:\tlearn: 7.5031981\ttotal: 45.4s\tremaining: 1m 51s\n",
      "87:\tlearn: 7.4875145\ttotal: 45.9s\tremaining: 1m 50s\n",
      "88:\tlearn: 7.4686364\ttotal: 46.4s\tremaining: 1m 50s\n",
      "89:\tlearn: 7.4573477\ttotal: 46.8s\tremaining: 1m 49s\n",
      "90:\tlearn: 7.4378312\ttotal: 47.3s\tremaining: 1m 48s\n",
      "91:\tlearn: 7.4267873\ttotal: 47.8s\tremaining: 1m 48s\n",
      "92:\tlearn: 7.4160510\ttotal: 48.3s\tremaining: 1m 47s\n",
      "93:\tlearn: 7.3936183\ttotal: 48.7s\tremaining: 1m 46s\n",
      "94:\tlearn: 7.3794147\ttotal: 49.2s\tremaining: 1m 46s\n",
      "95:\tlearn: 7.3575723\ttotal: 49.7s\tremaining: 1m 45s\n",
      "96:\tlearn: 7.3345225\ttotal: 50.3s\tremaining: 1m 45s\n",
      "97:\tlearn: 7.3120385\ttotal: 50.7s\tremaining: 1m 44s\n",
      "98:\tlearn: 7.2937510\ttotal: 51.3s\tremaining: 1m 44s\n",
      "99:\tlearn: 7.2770289\ttotal: 51.9s\tremaining: 1m 43s\n",
      "100:\tlearn: 7.2531155\ttotal: 52.5s\tremaining: 1m 43s\n",
      "101:\tlearn: 7.2218946\ttotal: 53s\tremaining: 1m 42s\n",
      "102:\tlearn: 7.1963383\ttotal: 53.6s\tremaining: 1m 42s\n",
      "103:\tlearn: 7.1879651\ttotal: 54.2s\tremaining: 1m 42s\n",
      "104:\tlearn: 7.1789216\ttotal: 54.8s\tremaining: 1m 41s\n",
      "105:\tlearn: 7.1587585\ttotal: 55.4s\tremaining: 1m 41s\n",
      "106:\tlearn: 7.1440806\ttotal: 55.9s\tremaining: 1m 40s\n",
      "107:\tlearn: 7.1325213\ttotal: 56.4s\tremaining: 1m 40s\n",
      "108:\tlearn: 7.1155376\ttotal: 57s\tremaining: 1m 39s\n",
      "109:\tlearn: 7.1080480\ttotal: 57.5s\tremaining: 1m 39s\n",
      "110:\tlearn: 7.0800918\ttotal: 57.9s\tremaining: 1m 38s\n",
      "111:\tlearn: 7.0692851\ttotal: 58.3s\tremaining: 1m 37s\n",
      "112:\tlearn: 7.0595275\ttotal: 58.8s\tremaining: 1m 37s\n",
      "113:\tlearn: 7.0452388\ttotal: 59.4s\tremaining: 1m 36s\n",
      "114:\tlearn: 7.0336813\ttotal: 60s\tremaining: 1m 36s\n",
      "115:\tlearn: 7.0260408\ttotal: 1m\tremaining: 1m 35s\n",
      "116:\tlearn: 7.0234210\ttotal: 1m\tremaining: 1m 35s\n",
      "117:\tlearn: 6.9998534\ttotal: 1m 1s\tremaining: 1m 34s\n",
      "118:\tlearn: 6.9861994\ttotal: 1m 1s\tremaining: 1m 34s\n",
      "119:\tlearn: 6.9785401\ttotal: 1m 2s\tremaining: 1m 33s\n",
      "120:\tlearn: 6.9740680\ttotal: 1m 2s\tremaining: 1m 33s\n",
      "121:\tlearn: 6.9511092\ttotal: 1m 3s\tremaining: 1m 32s\n",
      "122:\tlearn: 6.9304618\ttotal: 1m 3s\tremaining: 1m 32s\n",
      "123:\tlearn: 6.9181652\ttotal: 1m 4s\tremaining: 1m 31s\n",
      "124:\tlearn: 6.8971552\ttotal: 1m 4s\tremaining: 1m 30s\n",
      "125:\tlearn: 6.8830641\ttotal: 1m 5s\tremaining: 1m 30s\n",
      "126:\tlearn: 6.8728474\ttotal: 1m 5s\tremaining: 1m 29s\n",
      "127:\tlearn: 6.8678494\ttotal: 1m 6s\tremaining: 1m 29s\n",
      "128:\tlearn: 6.8484318\ttotal: 1m 6s\tremaining: 1m 28s\n",
      "129:\tlearn: 6.8227383\ttotal: 1m 7s\tremaining: 1m 27s\n",
      "130:\tlearn: 6.8139677\ttotal: 1m 7s\tremaining: 1m 27s\n",
      "131:\tlearn: 6.8049362\ttotal: 1m 8s\tremaining: 1m 26s\n",
      "132:\tlearn: 6.7922601\ttotal: 1m 8s\tremaining: 1m 26s\n",
      "133:\tlearn: 6.7884021\ttotal: 1m 9s\tremaining: 1m 25s\n",
      "134:\tlearn: 6.7784947\ttotal: 1m 9s\tremaining: 1m 25s\n",
      "135:\tlearn: 6.7718845\ttotal: 1m 10s\tremaining: 1m 24s\n",
      "136:\tlearn: 6.7559015\ttotal: 1m 10s\tremaining: 1m 24s\n",
      "137:\tlearn: 6.7466470\ttotal: 1m 11s\tremaining: 1m 23s\n",
      "138:\tlearn: 6.7325178\ttotal: 1m 11s\tremaining: 1m 23s\n",
      "139:\tlearn: 6.7294900\ttotal: 1m 12s\tremaining: 1m 22s\n",
      "140:\tlearn: 6.7184674\ttotal: 1m 12s\tremaining: 1m 22s\n",
      "141:\tlearn: 6.7096074\ttotal: 1m 13s\tremaining: 1m 21s\n",
      "142:\tlearn: 6.7038820\ttotal: 1m 13s\tremaining: 1m 21s\n",
      "143:\tlearn: 6.6892046\ttotal: 1m 14s\tremaining: 1m 20s\n",
      "144:\tlearn: 6.6826808\ttotal: 1m 14s\tremaining: 1m 20s\n",
      "145:\tlearn: 6.6784445\ttotal: 1m 15s\tremaining: 1m 19s\n",
      "146:\tlearn: 6.6683658\ttotal: 1m 16s\tremaining: 1m 19s\n",
      "147:\tlearn: 6.6630940\ttotal: 1m 16s\tremaining: 1m 18s\n",
      "148:\tlearn: 6.6498510\ttotal: 1m 17s\tremaining: 1m 18s\n",
      "149:\tlearn: 6.6393887\ttotal: 1m 17s\tremaining: 1m 17s\n",
      "150:\tlearn: 6.6271166\ttotal: 1m 18s\tremaining: 1m 17s\n",
      "151:\tlearn: 6.6146433\ttotal: 1m 18s\tremaining: 1m 16s\n",
      "152:\tlearn: 6.5998145\ttotal: 1m 19s\tremaining: 1m 16s\n",
      "153:\tlearn: 6.5943373\ttotal: 1m 19s\tremaining: 1m 15s\n",
      "154:\tlearn: 6.5788155\ttotal: 1m 20s\tremaining: 1m 15s\n",
      "155:\tlearn: 6.5709293\ttotal: 1m 20s\tremaining: 1m 14s\n",
      "156:\tlearn: 6.5572110\ttotal: 1m 21s\tremaining: 1m 14s\n",
      "157:\tlearn: 6.5516520\ttotal: 1m 21s\tremaining: 1m 13s\n",
      "158:\tlearn: 6.5484089\ttotal: 1m 22s\tremaining: 1m 12s\n",
      "159:\tlearn: 6.5280684\ttotal: 1m 22s\tremaining: 1m 12s\n",
      "160:\tlearn: 6.5158724\ttotal: 1m 23s\tremaining: 1m 11s\n",
      "161:\tlearn: 6.5134628\ttotal: 1m 23s\tremaining: 1m 11s\n",
      "162:\tlearn: 6.4961806\ttotal: 1m 24s\tremaining: 1m 10s\n",
      "163:\tlearn: 6.4851771\ttotal: 1m 24s\tremaining: 1m 10s\n",
      "164:\tlearn: 6.4752039\ttotal: 1m 25s\tremaining: 1m 9s\n",
      "165:\tlearn: 6.4638219\ttotal: 1m 25s\tremaining: 1m 9s\n",
      "166:\tlearn: 6.4571147\ttotal: 1m 26s\tremaining: 1m 8s\n",
      "167:\tlearn: 6.4404229\ttotal: 1m 26s\tremaining: 1m 8s\n",
      "168:\tlearn: 6.4281455\ttotal: 1m 27s\tremaining: 1m 7s\n",
      "169:\tlearn: 6.4218315\ttotal: 1m 27s\tremaining: 1m 7s\n",
      "170:\tlearn: 6.4137342\ttotal: 1m 28s\tremaining: 1m 6s\n",
      "171:\tlearn: 6.4008802\ttotal: 1m 28s\tremaining: 1m 6s\n",
      "172:\tlearn: 6.3961050\ttotal: 1m 29s\tremaining: 1m 5s\n",
      "173:\tlearn: 6.3930157\ttotal: 1m 29s\tremaining: 1m 5s\n",
      "174:\tlearn: 6.3725779\ttotal: 1m 30s\tremaining: 1m 4s\n",
      "175:\tlearn: 6.3622142\ttotal: 1m 30s\tremaining: 1m 4s\n",
      "176:\tlearn: 6.3505681\ttotal: 1m 31s\tremaining: 1m 3s\n",
      "177:\tlearn: 6.3443656\ttotal: 1m 31s\tremaining: 1m 3s\n",
      "178:\tlearn: 6.3417186\ttotal: 1m 32s\tremaining: 1m 2s\n",
      "179:\tlearn: 6.3312701\ttotal: 1m 32s\tremaining: 1m 1s\n",
      "180:\tlearn: 6.3206812\ttotal: 1m 33s\tremaining: 1m 1s\n",
      "181:\tlearn: 6.3079491\ttotal: 1m 33s\tremaining: 1m\n",
      "182:\tlearn: 6.2977248\ttotal: 1m 34s\tremaining: 1m\n",
      "183:\tlearn: 6.2837299\ttotal: 1m 34s\tremaining: 59.9s\n",
      "184:\tlearn: 6.2747115\ttotal: 1m 35s\tremaining: 59.3s\n",
      "185:\tlearn: 6.2689011\ttotal: 1m 35s\tremaining: 58.8s\n",
      "186:\tlearn: 6.2529945\ttotal: 1m 36s\tremaining: 58.3s\n",
      "187:\tlearn: 6.2508713\ttotal: 1m 36s\tremaining: 57.8s\n",
      "188:\tlearn: 6.2361686\ttotal: 1m 37s\tremaining: 57.3s\n",
      "189:\tlearn: 6.2252857\ttotal: 1m 37s\tremaining: 56.7s\n",
      "190:\tlearn: 6.2192875\ttotal: 1m 38s\tremaining: 56.2s\n",
      "191:\tlearn: 6.2153386\ttotal: 1m 38s\tremaining: 55.7s\n",
      "192:\tlearn: 6.2084613\ttotal: 1m 39s\tremaining: 55.2s\n",
      "193:\tlearn: 6.2051726\ttotal: 1m 40s\tremaining: 54.7s\n",
      "194:\tlearn: 6.1964167\ttotal: 1m 40s\tremaining: 54.1s\n",
      "195:\tlearn: 6.1847877\ttotal: 1m 41s\tremaining: 53.6s\n",
      "196:\tlearn: 6.1726394\ttotal: 1m 41s\tremaining: 53.1s\n",
      "197:\tlearn: 6.1687953\ttotal: 1m 42s\tremaining: 52.5s\n",
      "198:\tlearn: 6.1557629\ttotal: 1m 42s\tremaining: 52.1s\n",
      "199:\tlearn: 6.1414391\ttotal: 1m 43s\tremaining: 51.5s\n",
      "200:\tlearn: 6.1323712\ttotal: 1m 43s\tremaining: 51.1s\n",
      "201:\tlearn: 6.1298992\ttotal: 1m 44s\tremaining: 50.5s\n",
      "202:\tlearn: 6.1186357\ttotal: 1m 44s\tremaining: 50s\n",
      "203:\tlearn: 6.0977012\ttotal: 1m 45s\tremaining: 49.5s\n",
      "204:\tlearn: 6.0862040\ttotal: 1m 45s\tremaining: 49s\n",
      "205:\tlearn: 6.0803232\ttotal: 1m 46s\tremaining: 48.5s\n",
      "206:\tlearn: 6.0678159\ttotal: 1m 46s\tremaining: 47.9s\n",
      "207:\tlearn: 6.0593149\ttotal: 1m 47s\tremaining: 47.4s\n",
      "208:\tlearn: 6.0490403\ttotal: 1m 47s\tremaining: 46.9s\n",
      "209:\tlearn: 6.0419327\ttotal: 1m 48s\tremaining: 46.4s\n",
      "210:\tlearn: 6.0330874\ttotal: 1m 48s\tremaining: 45.8s\n",
      "211:\tlearn: 6.0137559\ttotal: 1m 49s\tremaining: 45.3s\n",
      "212:\tlearn: 6.0102602\ttotal: 1m 49s\tremaining: 44.8s\n",
      "213:\tlearn: 6.0054451\ttotal: 1m 50s\tremaining: 44.3s\n",
      "214:\tlearn: 6.0033467\ttotal: 1m 50s\tremaining: 43.7s\n",
      "215:\tlearn: 5.9849813\ttotal: 1m 51s\tremaining: 43.2s\n",
      "216:\tlearn: 5.9793809\ttotal: 1m 51s\tremaining: 42.7s\n",
      "217:\tlearn: 5.9631511\ttotal: 1m 52s\tremaining: 42.2s\n",
      "218:\tlearn: 5.9565661\ttotal: 1m 52s\tremaining: 41.7s\n",
      "219:\tlearn: 5.9475280\ttotal: 1m 53s\tremaining: 41.2s\n",
      "220:\tlearn: 5.9314695\ttotal: 1m 53s\tremaining: 40.7s\n",
      "221:\tlearn: 5.9243329\ttotal: 1m 54s\tremaining: 40.2s\n",
      "222:\tlearn: 5.9156149\ttotal: 1m 54s\tremaining: 39.7s\n",
      "223:\tlearn: 5.9109805\ttotal: 1m 55s\tremaining: 39.2s\n",
      "224:\tlearn: 5.9081930\ttotal: 1m 56s\tremaining: 38.7s\n",
      "225:\tlearn: 5.9010667\ttotal: 1m 56s\tremaining: 38.2s\n",
      "226:\tlearn: 5.8933081\ttotal: 1m 57s\tremaining: 37.6s\n",
      "227:\tlearn: 5.8899655\ttotal: 1m 57s\tremaining: 37.1s\n",
      "228:\tlearn: 5.8806824\ttotal: 1m 58s\tremaining: 36.6s\n",
      "229:\tlearn: 5.8685342\ttotal: 1m 58s\tremaining: 36.1s\n",
      "230:\tlearn: 5.8655771\ttotal: 1m 59s\tremaining: 35.6s\n",
      "231:\tlearn: 5.8523347\ttotal: 1m 59s\tremaining: 35.1s\n",
      "232:\tlearn: 5.8475056\ttotal: 2m\tremaining: 34.6s\n",
      "233:\tlearn: 5.8398948\ttotal: 2m\tremaining: 34.1s\n",
      "234:\tlearn: 5.8266413\ttotal: 2m 1s\tremaining: 33.5s\n",
      "235:\tlearn: 5.8077202\ttotal: 2m 1s\tremaining: 33s\n",
      "236:\tlearn: 5.7963821\ttotal: 2m 2s\tremaining: 32.5s\n",
      "237:\tlearn: 5.7912706\ttotal: 2m 2s\tremaining: 32s\n",
      "238:\tlearn: 5.7880153\ttotal: 2m 3s\tremaining: 31.5s\n",
      "239:\tlearn: 5.7858433\ttotal: 2m 3s\tremaining: 31s\n",
      "240:\tlearn: 5.7790485\ttotal: 2m 4s\tremaining: 30.4s\n",
      "241:\tlearn: 5.7608510\ttotal: 2m 4s\tremaining: 29.9s\n",
      "242:\tlearn: 5.7516032\ttotal: 2m 5s\tremaining: 29.4s\n",
      "243:\tlearn: 5.7472163\ttotal: 2m 5s\tremaining: 28.9s\n",
      "244:\tlearn: 5.7416142\ttotal: 2m 6s\tremaining: 28.4s\n",
      "245:\tlearn: 5.7235895\ttotal: 2m 6s\tremaining: 27.9s\n",
      "246:\tlearn: 5.7154080\ttotal: 2m 7s\tremaining: 27.4s\n",
      "247:\tlearn: 5.7066901\ttotal: 2m 7s\tremaining: 26.8s\n",
      "248:\tlearn: 5.7015578\ttotal: 2m 8s\tremaining: 26.3s\n",
      "249:\tlearn: 5.6950372\ttotal: 2m 8s\tremaining: 25.8s\n",
      "250:\tlearn: 5.6872718\ttotal: 2m 9s\tremaining: 25.3s\n",
      "251:\tlearn: 5.6735744\ttotal: 2m 9s\tremaining: 24.7s\n",
      "252:\tlearn: 5.6653773\ttotal: 2m 10s\tremaining: 24.2s\n",
      "253:\tlearn: 5.6609642\ttotal: 2m 10s\tremaining: 23.7s\n",
      "254:\tlearn: 5.6571432\ttotal: 2m 11s\tremaining: 23.2s\n",
      "255:\tlearn: 5.6510894\ttotal: 2m 11s\tremaining: 22.6s\n",
      "256:\tlearn: 5.6449231\ttotal: 2m 12s\tremaining: 22.1s\n",
      "257:\tlearn: 5.6377760\ttotal: 2m 12s\tremaining: 21.6s\n",
      "258:\tlearn: 5.6363744\ttotal: 2m 13s\tremaining: 21.1s\n",
      "259:\tlearn: 5.6270574\ttotal: 2m 13s\tremaining: 20.6s\n",
      "260:\tlearn: 5.6254956\ttotal: 2m 14s\tremaining: 20.1s\n",
      "261:\tlearn: 5.6218049\ttotal: 2m 14s\tremaining: 19.6s\n",
      "262:\tlearn: 5.6193647\ttotal: 2m 15s\tremaining: 19s\n",
      "263:\tlearn: 5.6122029\ttotal: 2m 15s\tremaining: 18.5s\n",
      "264:\tlearn: 5.6092570\ttotal: 2m 16s\tremaining: 18s\n",
      "265:\tlearn: 5.6049633\ttotal: 2m 16s\tremaining: 17.5s\n",
      "266:\tlearn: 5.5960641\ttotal: 2m 17s\tremaining: 17s\n",
      "267:\tlearn: 5.5901052\ttotal: 2m 17s\tremaining: 16.5s\n",
      "268:\tlearn: 5.5800361\ttotal: 2m 18s\tremaining: 15.9s\n",
      "269:\tlearn: 5.5774744\ttotal: 2m 18s\tremaining: 15.4s\n",
      "270:\tlearn: 5.5659110\ttotal: 2m 19s\tremaining: 14.9s\n",
      "271:\tlearn: 5.5615101\ttotal: 2m 19s\tremaining: 14.4s\n",
      "272:\tlearn: 5.5562470\ttotal: 2m 20s\tremaining: 13.9s\n",
      "273:\tlearn: 5.5547655\ttotal: 2m 21s\tremaining: 13.4s\n",
      "274:\tlearn: 5.5481621\ttotal: 2m 21s\tremaining: 12.9s\n",
      "275:\tlearn: 5.5429206\ttotal: 2m 22s\tremaining: 12.4s\n",
      "276:\tlearn: 5.5339299\ttotal: 2m 22s\tremaining: 11.8s\n",
      "277:\tlearn: 5.5305010\ttotal: 2m 23s\tremaining: 11.3s\n",
      "278:\tlearn: 5.5284958\ttotal: 2m 23s\tremaining: 10.8s\n",
      "279:\tlearn: 5.5214408\ttotal: 2m 24s\tremaining: 10.3s\n",
      "280:\tlearn: 5.5163654\ttotal: 2m 25s\tremaining: 9.82s\n",
      "281:\tlearn: 5.5097816\ttotal: 2m 25s\tremaining: 9.32s\n",
      "282:\tlearn: 5.5056251\ttotal: 2m 26s\tremaining: 8.81s\n",
      "283:\tlearn: 5.5020613\ttotal: 2m 27s\tremaining: 8.29s\n",
      "284:\tlearn: 5.4923950\ttotal: 2m 27s\tremaining: 7.77s\n",
      "285:\tlearn: 5.4818745\ttotal: 2m 28s\tremaining: 7.26s\n",
      "286:\tlearn: 5.4801482\ttotal: 2m 28s\tremaining: 6.74s\n",
      "287:\tlearn: 5.4735532\ttotal: 2m 29s\tremaining: 6.22s\n",
      "288:\tlearn: 5.4701836\ttotal: 2m 29s\tremaining: 5.7s\n",
      "289:\tlearn: 5.4668144\ttotal: 2m 30s\tremaining: 5.18s\n",
      "290:\tlearn: 5.4596613\ttotal: 2m 30s\tremaining: 4.67s\n",
      "291:\tlearn: 5.4471919\ttotal: 2m 31s\tremaining: 4.15s\n",
      "292:\tlearn: 5.4442497\ttotal: 2m 31s\tremaining: 3.63s\n",
      "293:\tlearn: 5.4316473\ttotal: 2m 32s\tremaining: 3.11s\n",
      "294:\tlearn: 5.4295566\ttotal: 2m 32s\tremaining: 2.59s\n",
      "295:\tlearn: 5.4256593\ttotal: 2m 33s\tremaining: 2.07s\n",
      "296:\tlearn: 5.4215751\ttotal: 2m 33s\tremaining: 1.55s\n",
      "297:\tlearn: 5.4167126\ttotal: 2m 34s\tremaining: 1.03s\n",
      "298:\tlearn: 5.4121871\ttotal: 2m 34s\tremaining: 518ms\n",
      "299:\tlearn: 5.4108529\ttotal: 2m 35s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "1 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\xgboost\\training.py\", line 196, in train\n",
      "    return bst.copy()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 1765, in copy\n",
      "    return copy.copy(self)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PC\\anaconda3\\Lib\\copy.py\", line 84, in copy\n",
      "    return copier(x)\n",
      "           ^^^^^^^^^\n",
      "  File \"C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 1751, in __copy__\n",
      "    return self.__deepcopy__(None)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 1755, in __deepcopy__\n",
      "    return Booster(model_file=self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 1562, in __init__\n",
      "    state = model_file.__getstate__()\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 1663, in __getstate__\n",
      "    _check_call(_LIB.XGBoosterSerializeToBuffer(self.handle,\n",
      "  File \"C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: bad allocation\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [ -2.6817949   -1.51986238  -2.24759619  -2.81810453  -1.9600107\n",
      "  -2.85035627  -1.10848684  -1.35759617  -6.83592363  -2.07955545\n",
      " -16.73691909  -1.41889897  -1.26709013  -1.20534901  -2.02344586\n",
      "  -2.87986315 -17.28617934  -1.97599023  -2.29920559 -16.78485689\n",
      "  -1.62219799 -43.12528401  -2.232149   -16.12730147  -1.18745912\n",
      "  -1.7594891  -43.12784777  -1.44139134  -1.28980017  -1.00229489\n",
      "  -6.61647962  -6.37927784  -6.8344039   -1.7561287  -16.3486659\n",
      "  -1.23602318  -6.37611722  -2.08497602  -1.56930693 -17.28311421\n",
      "  -6.37627562  -2.84037324 -16.31435435  -1.40961435  -1.24624844\n",
      "  -1.81230606  -1.54450562  -1.11596233  -1.55421722          nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on training data for lgb: 1.36\n",
      "MAE on test data for lgb: 1.36\n",
      "MAE on training data for catboost: 1.48\n",
      "MAE on test data for catboost: 1.50\n",
      "MAE on training data for xgb: 0.78\n",
      "MAE on test data for xgb: 0.93\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>Net Power (MW)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-01 00:00:00</td>\n",
       "      <td>8.738863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-01 00:01:00</td>\n",
       "      <td>8.738863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-01 00:02:00</td>\n",
       "      <td>8.738863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-01 00:03:00</td>\n",
       "      <td>8.738863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-01 00:04:00</td>\n",
       "      <td>8.738863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time  Net Power (MW)\n",
       "0 2022-04-01 00:00:00        8.738863\n",
       "1 2022-04-01 00:01:00        8.738863\n",
       "2 2022-04-01 00:02:00        8.738863\n",
       "3 2022-04-01 00:03:00        8.738863\n",
       "4 2022-04-01 00:04:00        8.738863"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Load your dataset (replace 'your_dataset.csv' with your actual data)\n",
    "data = pd.read_csv(\"C:/Users/PC/Downloads/challenge_22/challenge_22_data/train.csv\", delimiter=\";\", decimal=\",\", na_values=[\"#VALEUR!\"], index_col=\"time\")\n",
    "data.index = pd.to_datetime(data.index, format='%d/%m/%Y %H:%M')\n",
    "data.drop(columns=['Network Frequency (Hz)' , 'CTRL anti givrage' ], inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "test = pd.read_csv(\"C:/Users/PC/Downloads/challenge_22/challenge_22_data/test.csv\", delimiter=\";\", decimal=\",\", na_values=[\"#VALEUR!\"], index_col=\"time\")\n",
    "test.index = pd.to_datetime(test.index, format='%d/%m/%Y %H:%M')\n",
    "test.drop(columns=['Network Frequency (Hz)' , 'CTRL anti givrage' ], inplace=True)\n",
    "\n",
    "# Assuming your dataset has columns 'Feature1', 'Feature2', ..., 'Feature11', and 'Energy_Output'\n",
    "# Modify these feature names accordingly to match your dataset\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop(columns=\"Net Power (MW)\")\n",
    "y = data[\"Net Power (MW)\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Remove outliers from the target variable (optional)\n",
    "q1 = np.percentile(y_train, 25)\n",
    "q3 = np.percentile(y_train, 75)\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "y_train = np.clip(y_train, lower_bound, upper_bound)\n",
    "\n",
    "# Initialize the models\n",
    "lgb_model = lgb.LGBMRegressor(random_state=42)\n",
    "catboost_model = CatBoostRegressor(random_state=42)\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Hyperparameter tuning using RandomizedSearchCV\n",
    "param_distributions_lgb = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'num_leaves': [20, 30, 40],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [0, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "param_distributions_catboost = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bylevel': [0.8, 0.9, 1.0],\n",
    "    'reg_lambda': [0, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "param_distributions_xgb = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [0, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "models = {\n",
    "    'lgb': lgb_model,\n",
    "    'catboost': catboost_model,\n",
    "    'xgb': xgb_model\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    if model_name == 'lgb':\n",
    "        random_search = RandomizedSearchCV(estimator=model, param_distributions=param_distributions_lgb, n_iter=50, cv=3, scoring='neg_mean_absolute_error', random_state=42, n_jobs=-1)\n",
    "    elif model_name == 'catboost':\n",
    "        random_search = RandomizedSearchCV(estimator=model, param_distributions=param_distributions_catboost, n_iter=50, cv=3, scoring='neg_mean_absolute_error', random_state=42, n_jobs=-1)\n",
    "    else:\n",
    "        random_search = RandomizedSearchCV(estimator=model, param_distributions=param_distributions_xgb, n_iter=50, cv=3, scoring='neg_mean_absolute_error', random_state=42, n_jobs=-1)\n",
    "    \n",
    "    random_search.fit(X_train, y_train)\n",
    "    best_model = random_search.best_estimator_\n",
    "    best_models[model_name] = best_model\n",
    "\n",
    "# Evaluate models on training and test data\n",
    "for model_name, model in best_models.items():\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    mae_test = mean_absolute_error(y_train, y_train_pred)\n",
    "    print(f\"MAE on training data for {model_name}: {mae_test:.2f}\")\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "    print(f\"MAE on test data for {model_name}: {mae_test:.2f}\")\n",
    "\n",
    "# Rest of the code for predictions and saving to CSV remains the same\n",
    "selected_model = best_models['lgb']\n",
    "a_test = test.drop(columns=\"Net Power (MW)\")\n",
    "\n",
    "df_NetWPower = pd.DataFrame({\n",
    "    'time': test.index,\n",
    "    'Net Power (MW)': selected_model.predict(a_test),\n",
    "})\n",
    "\n",
    "df_NetWPower.to_csv('data/NetWPower.csv', date_format='%d/%m/%Y %H:%M', index=False, sep=';')\n",
    "df_NetWPower.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c976bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>Net Power (MW)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-01 00:00:00</td>\n",
       "      <td>8.74460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-01 00:01:00</td>\n",
       "      <td>8.75024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-01 00:02:00</td>\n",
       "      <td>8.74460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-01 00:03:00</td>\n",
       "      <td>8.74460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-01 00:04:00</td>\n",
       "      <td>8.75024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time  Net Power (MW)\n",
       "0 2022-04-01 00:00:00         8.74460\n",
       "1 2022-04-01 00:01:00         8.75024\n",
       "2 2022-04-01 00:02:00         8.74460\n",
       "3 2022-04-01 00:03:00         8.74460\n",
       "4 2022-04-01 00:04:00         8.75024"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_model = best_models['xgb']\n",
    "a_test = test.drop(columns=\"Net Power (MW)\")\n",
    "\n",
    "df_NetWPower = pd.DataFrame({\n",
    "    'time': test.index,\n",
    "    'Net Power (MW)': selected_model.predict(a_test),\n",
    "})\n",
    "\n",
    "df_NetWPower.to_csv('data/NetWPower.csv', date_format='%d/%m/%Y %H:%M', index=False, sep=';')\n",
    "df_NetWPower.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de120eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>Net Power (MW)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-01 00:00:00</td>\n",
       "      <td>8.680746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-01 00:01:00</td>\n",
       "      <td>8.680746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-01 00:02:00</td>\n",
       "      <td>8.680746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-01 00:03:00</td>\n",
       "      <td>8.680746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-01 00:04:00</td>\n",
       "      <td>8.680746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time  Net Power (MW)\n",
       "0 2022-04-01 00:00:00        8.680746\n",
       "1 2022-04-01 00:01:00        8.680746\n",
       "2 2022-04-01 00:02:00        8.680746\n",
       "3 2022-04-01 00:03:00        8.680746\n",
       "4 2022-04-01 00:04:00        8.680746"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_model = best_models['catboost']\n",
    "a_test = test.drop(columns=\"Net Power (MW)\")\n",
    "\n",
    "df_NetWPower = pd.DataFrame({\n",
    "    'time': test.index,\n",
    "    'Net Power (MW)': selected_model.predict(a_test),\n",
    "})\n",
    "\n",
    "df_NetWPower.to_csv('data/NetWPower.csv', date_format='%d/%m/%Y %H:%M', index=False, sep=';')\n",
    "df_NetWPower.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "999a1eb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Net Power (MW)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m     20\u001b[0m X_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[1;32m---> 21\u001b[0m test_data_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(test_data)\n\u001b[0;32m     22\u001b[0m X \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNet Power (MW)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNet Power (MW)\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:992\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    989\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    991\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m--> 992\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    993\u001b[0m     X,\n\u001b[0;32m    994\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    995\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    996\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    997\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES,\n\u001b[0;32m    998\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    999\u001b[0m )\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1002\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:548\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    484\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    485\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    490\u001b[0m ):\n\u001b[0;32m    491\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \n\u001b[0;32m    493\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 548\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    551\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    552\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    553\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    554\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:481\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    477\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    479\u001b[0m     )\n\u001b[1;32m--> 481\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Net Power (MW)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from hyperopt import hp, tpe, fmin\n",
    "\n",
    "# Load and preprocess data as before\n",
    "data = pd.read_csv(\"C:/Users/PC/Downloads/challenge_22/challenge_22_data/train.csv\", delimiter=\";\", decimal=\",\", na_values=[\"#VALEUR!\"], index_col=\"time\")\n",
    "data.index = pd.to_datetime(data.index, format='%d/%m/%Y %H:%M')\n",
    "data.drop(columns=['Network Frequency (Hz)', 'CTRL anti givrage'], inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "test_data = pd.read_csv(\"C:/Users/PC/Downloads/challenge_22/challenge_22_data/test.csv\", delimiter=\";\", decimal=\",\", na_values=[\"#VALEUR!\"], index_col=\"time\")\n",
    "test_data.index = pd.to_datetime(test_data.index, format='%d/%m/%Y %H:%M')\n",
    "test_data.drop(columns=['Network Frequency (Hz)', 'CTRL anti givrage'], inplace=True)\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "test_data_scaled = scaler.transform(test_data)\n",
    "X = data.drop(columns=\"Net Power (MW)\")\n",
    "y = data[\"Net Power (MW)\"]\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Hyperparameter Tuning using Bayesian Optimization\n",
    "space = {\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "    'max_depth': hp.choice('max_depth', np.arange(5, 15, dtype=int)),\n",
    "    'num_leaves': hp.choice('num_leaves', np.arange(30, 150, dtype=int)),\n",
    "    # Add more hyperparameters here\n",
    "}\n",
    "\n",
    "def objective(params):\n",
    "    model = lgb.LGBMRegressor(**params, random_state=42)\n",
    "    model.fit(X_scaled, y_train)\n",
    "    y_val_pred = model.predict(X_val_scaled)\n",
    "    return mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=50, verbose=1)\n",
    "\n",
    "# Train the final model with best hyperparameters on the entire training data\n",
    "final_model = lgb.LGBMRegressor(**best, random_state=42)\n",
    "final_model.fit(X_scaled, y)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_test_pred = final_model.predict(test_data_scaled)\n",
    "\n",
    "# Create a DataFrame with the predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'time': test.index,\n",
    "    'Net Power (MW)': y_test_pred,})\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "predicti_df.to_csv(\"predicti.csv\", index=False , date_format='%d/%m/%Y %H:%M', index=False, sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a2bd97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
